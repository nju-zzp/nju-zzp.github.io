<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Kafka Start | River&#39;s BLOG</title>
<meta name="keywords" content="">
<meta name="description" content="kafka 入门指南
1. kafka 基本概念与基本架构
2. kafka 单机环境搭建 与 启动">
<meta name="author" content="River">
<link rel="canonical" href="http://124.222.233.153/posts/tech/se/kafka-start/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.1daf73e1554b072225da652aa70423e50c557f664ef1cffeb43e526e1a26b8b8.css" integrity="sha256-Ha9z4VVLByIl2mUqpwQj5QxVf2ZO8c/&#43;tD5SbhomuLg=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://124.222.233.153/icons/pixel-blue.JPG">
<link rel="icon" type="image/png" sizes="16x16" href="http://124.222.233.153/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://124.222.233.153/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://124.222.233.153/apple-touch-icon.png">
<link rel="mask-icon" href="http://124.222.233.153/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Kafka Start" />
<meta property="og:description" content="kafka 入门指南
1. kafka 基本概念与基本架构
2. kafka 单机环境搭建 与 启动" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://124.222.233.153/posts/tech/se/kafka-start/" />
<meta property="og:image" content="http://124.222.233.153/images/kafka.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-07T23:33:20+08:00" />
<meta property="article:modified_time" content="2023-03-07T23:33:20+08:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://124.222.233.153/images/kafka.png" />
<meta name="twitter:title" content="Kafka Start"/>
<meta name="twitter:description" content="kafka 入门指南
1. kafka 基本概念与基本架构
2. kafka 单机环境搭建 与 启动"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Essays",
      "item": "http://124.222.233.153/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "🤖 Technology",
      "item": "http://124.222.233.153/posts/tech/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "🧑‍💻 Software Engineering",
      "item": "http://124.222.233.153/posts/tech/se/"
    }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "Kafka Start",
      "item": "http://124.222.233.153/posts/tech/se/kafka-start/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Kafka Start",
  "name": "Kafka Start",
  "description": "kafka 入门指南 1. kafka 基本概念与基本架构 2. kafka 单机环境搭建 与 启动",
  "keywords": [
    ""
  ],
  "articleBody": "kafka 入门指南 1. kafka 基本概念与基本架构 2. kafka 单机环境搭建 与 启动 参考：\nhttps://blog.csdn.net/CSDN877425287/article/details/108836682 https://www.cnblogs.com/qpf1/p/9161742.html 扩展（kafka生产环境部署指南）:\nkafka生产环境部署指南\n2.1 下载Kafka安装包上传服务器 kafka官网\nscp 指令上传服务器\ntar xzvf kafka_2.12-2.1.0.tgz -C /home/ubuntu/environments\n2.2 配置zookeeper配置 无需单独下载，已经集成\nvim ./kafka_2.12-2.1.0/config/zookeeper.properties\n如果kafka和zk是单节点运行的话使用kafka的默认配置即可\n#集群配置-单节点无需配置 server.1=192.168.0.187:2888:3888 server.2=192.168.0.188:2888:3888 server.3=192.168.0.189:2888:3888 dataDir zk数据存放目录\ndataLogDir zk日志存放目录\nclientPort 客户端连接zk服务的端口\ntickTime zk服务器之间或者客户端与服务器之间维持心跳的时间间隔\ninitLimit 允许follower（相对于Leaderer言的，客户端）连接并同步到Leader的初始化连接时间，以tickTime为单位，当初始化连接时间超过该值，则表示连接失败。\nsyncLimit Leader于Follower之间发送消息时，请求和答应时间长度，如果follow在设置时间内不能与leader通信，那么此follower将会被丢弃\nserver.1=192.168.0.187:2888:3888 2888是follower于leader减缓信息的端口，3888当leader交换信息的端口，3888是当leader挂了时用来执行选举是服务器互相通信的端口\n2.3 配置kafka配置（server） 如果kafka和zk是单节点运行的话使用kafka的默认配置即可\n关键：\nlog.dirs和zookeeper.connect。前者是日志存放文件夹，后者是zookeeper连接地址（端口和clientPort保持一致）。\nlisteners advertised.listeners（对外宣扬/暴露的地址和端口，比如对生产者、消费者暴露） 在公司内网部署 kafka 集群只需要用到 listeners，内外网需要作区分时 才需要用到advertised.listeners。\nadvertised_listeners 监听器会注册在 zookeeper 中；\n当我们对 172.17.0.10:9092 请求建立连接，kafka 服务器会通过 zookeeper 中注册的监听器，找到 INSIDE 监听器，然后通过 listeners 中找到对应的 通讯 ip 和 端口；\n同理，当我们对 \u003c公网 ip\u003e:端口 请求建立连接，kafka 服务器会通过 zookeeper 中注册的监听器，找到 OUTSIDE 监听器，然后通过 listeners 中找到对应的 通讯 ip 和 端口 172.17.0.10:9094；\n总结：advertised_listeners 是对外暴露的服务端口，真正建立连接用的是 listeners。\n只有内网，比如在公司搭建的 kafka 集群，只有内网中的服务可以用，这种情况下，只需要用 listeners 就行。 内外网，比如在 docker 中或者 在类似阿里云主机上部署 kafka 集群，这种情况下是 需要用到 advertised_listeners broker.id=0\t每个server需要单独配置broker.id如果不配置系统会指定配置，需要和上一步ID一致 listeners=PLAINTEST://ip:9092\t监听地址，格式PLAINTEST：//ip：端口 num.network.threads=3\t接收和发送网络信息的线程数 num.io.threads=8\t服务器用于处理请求的线程数，其中可能包括磁盘IO socket.send.buffer.bytes=102400\t套接字服务器使用的发送缓冲区（SO_SNDBUF） socket.receive.buffer.bytes=102400\t套接字服务器使用的接收缓冲区（SO_RCVBUF） socket.request.max.bytes=104857600\t套接字服务器将接收的请求最大大小（防止OOM） log.dirs=/tmp/kafka-logs\t日志文件 num.partitions=1\tpartitions的数量 num.recovery.threads.per.data.dir=1\t启动时恢复日志，关闭时刷盘日志每个数据目录的线程的数量，默认1 offsets.topic.replication.factor=1\t偏移量话题的复制因子（设置更高保证可用），为保证有效的父子，偏移量的复制因子是可配置的，在偏移话题的第一次请求的时候可用borker的数量至少为复制因子的大小，否则要么话题创建失败，要么复制因子取可用的数量和配置复制因子取最小值 transaction.state.log.replication.factor=1 transaction.state.log.min.isr=1 log.retention.hours=168\t日志文件删除之前保留的时间 log.segment.bytes=1073741824\t单个日志文件大小默认为1073741824 log.retention.check.interval.ms=300000\t检查日志端以查看是否可以根据保留策略删除他们的时间鳄梨 zookeeper.connect=zkip:2181\tzk主机地址，如果是zk集群以逗号分隔 zookeeper.connection.timeout.ms=6000\t连接zk的超时时间 group.initial.rebalance.delay.ms=0 2.4 后台启动zookeeper并检验是否运行成功 cd kafka_2.12-2.1.0/ nohup bin/zookeeper-server-start.sh config/zookeeper.properties \u0026 nohup bin/zookeeper-server-start.sh config/zookeeper.properties \u003e zookeeper-run.log 2\u003e\u00261 \u0026 echo conf | nc localhost 2181 echo stat | nc localhost 2181 2.5 后台启动kafka nohup bin/kafka-server-start.sh config/server.properties \u003e kafka-run.log 2\u003e\u00261 \u0026 2.6 创建并查看topic ubuntu$\u003e ./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test Created topic \"test\". ubuntu$\u003e ./bin/kafka-topics.sh --zookeeper localhost:2181 --list test 3. JAVA实现 Kafka Producer 3.1 方式一：kafka-clients API参考：https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html\n生产者详解、进阶参考：https://www.jianshu.com/p/37ea14d1d4ab（主要包含生产者参数配置、消息序列化、自定义分区）\n引入kafka-clients依赖 org.apache.kafka kafka-clients 2.1.0 创建生产者 KafkaProducer KafkaProducer API: https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html\n向 Kafka 写入消息，首先要创建一个生产者对象，该对象有3个必要属性。\nbootstrap.servers 指定 broker 的地址列表，地址的格式为 host:port。 不需要包含所有的 broker 地址，生产者会通过给定的 broker 查找到其他 broker 的信息。建议至少提供两个 broker 的信息，防止其中一个宕机。 key.serializer Kafka 客户端默认提供了 ByteArraySerializer、 StringSerializer 和 IntegerSerializer，因此如果使用常见的 Java 对象类型，不需要实现自己的序列化器 。如果要自定义序列化器，需要实现 org.apache.kafka.common.serialization.Serializer 接口。 需要注意，key.serializer 是必须设置的，即使只发送值类型。 value.serializer 与 key.serializer 一样， value.serializer 指定的类会将值序列化发送给 broker。 Properties kafkaProps = new Properties(); kafkaProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"kafka-broker-ip:9092\"); kafkaProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); kafkaProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); KafkaProducer producer = new KafkaProducer(kafkaProps); 发送消息 实例化生产者对象后，就可以开始送消息了。发送消息主要有以下 3 种方式：\n发送并忘记（fire-and-forget） 把消息发送给服务器，不关心是否正常到达。大多数情况下，消息会正常到达，因为 Kafka 是高可用的，而且生产者会自动尝试重发。不过，使用这种方式有时候也会丢失一些消息。 同步发送（async） 使用 send() 方法发送消息，会返回一个 Future 对象，调用 get() 方法阻塞等待返回，返回结果知道是否发送成功。 异步发送（sync）（最简单最常用） 使用 send() 方法并指定一个回调函数，服务器在返回响应时调用该函数。 核心对象：\n消息对象 ProducerRecord : https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html 消息记录的存储信息 RecordMetadata： https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html（send(...).get()返回对象） 例子使用了ScheduledExecutorServive（即ScheduledThreadPool）来进行定时任务\nScheduledExecutorService scheduledExecutor = Executors.newScheduledThreadPool(5); scheduledExecutor.scheduleAtFixedRate(() -\u003e { try { RecordMetadata recordMetadata = producer.send(new ProducerRecord(\"test\", \"time\", new Date().toString())).get(); System.out.println(\"Success: OFFSET-\"+recordMetadata.offset()); } catch (InterruptedException e) { System.out.println(\"ERROR\"); throw new RuntimeException(e); } catch (ExecutionException e) { System.out.println(\"ERROR\"); throw new RuntimeException(e); } }, 0, 2, TimeUnit.SECONDS); 4. JAVA实现 Kafka Consumer 4.1 方式一：kaf登录，文件提交后自动重命名，支持收集任意格式文件。 搭配坚果云ka-clients\nAPI 参考：https://kafka.apache.org/33/javadoc/org/apache/kafka/clients/consumer/package-frame.html\n消费者详解、进阶参考：https://www.jianshu.com/p/1f9e18e926f6（主要包括消费者参数配置\n引入kafka-clients依赖 org.apache.kafka kafka-clients 2.1.0 创建消费者 KafkaConsumer KafkaConsumer对象API：https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html ConsumerConfig API：https://kafka.apache.org/33/javadoc/org/apache/kafka/clients/consumer/ConsumerConfig.html auto.offset.reset：当不存在初始偏移量或服务器上不再存在当前偏移量时，此属性是必需的。只有以下三个值可用于重置偏移值：\nWhat to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server (e.g. because that data has been deleted):\nearliest: automatically reset the offset to the earliest offsetlatest: automatically reset the offset to the latest offsetnone: throw exception to the consumer if no previous offset is found for the consumer\\'s groupanything else: throw exception to the consumer. 指定了消费者在读取一个没有偏移量（offset）的分区或者偏移量无效的情况下（因消费者长时间失效，包含偏移量的记录已经过时井被删除）该作何处理，默认值是 latest，表示在 offset 无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）。\nProperties props = new Properties(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \"124.222.233.153:9092\"); props.put(ConsumerConfig.GROUP_ID_CONFIG, \"191870267-0\"); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\"); props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, \"10\"); KafkaConsumer consumer = new KafkaConsumer(props); 订阅主题Topic consumer.subscribe(Collections.singleton(\"test\")); 消费轮询（核心） 消息轮询是消费者的核心，通过轮询向服务器请求数据。消息轮询 API 会处理所有的细节，包括群组协调、分区再均衡、发送心跳和获取数据，开发者只需要处理从分区返回的数据。\nwhile (true) { ConsumerRecords records = consumer.poll(Duration.ofSeconds(5)); for(ConsumerRecord record : records) { System.out.println(\"{offset=\" + record.offset() + \" , key=\" + record.key() + \" , value=\" + record.value() + \" , timestamp=\" + record.timestamp() + \" }\"); } System.out.println(); } ",
  "wordCount" : "3444",
  "inLanguage": "en",
  "image":"http://124.222.233.153/images/kafka.png","datePublished": "2023-03-07T23:33:20+08:00",
  "dateModified": "2023-03-07T23:33:20+08:00",
  "author":[{
    "@type": "Person",
    "name": "River"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://124.222.233.153/posts/tech/se/kafka-start/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "River's BLOG",
    "logo": {
      "@type": "ImageObject",
      "url": "http://124.222.233.153/icons/pixel-blue.JPG"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://124.222.233.153/" accesskey="h" title="River&#39;s BLOG (Alt + H)">
                <img src="http://124.222.233.153/icons/pixel-blue.JPG" alt="" aria-label="logo"
                    height="35">River&#39;s BLOG</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://124.222.233.153/posts/" title="Essays">
                    <span>Essays</span>
                </a>
            </li>
            <li>
                <a href="http://124.222.233.153/archives/" title="Time">
                    <span>Time</span>
                </a>
            </li>
            <li>
                <a href="http://124.222.233.153/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://124.222.233.153/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://124.222.233.153/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://124.222.233.153/friends" title="Friends">
                    <span>Friends</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://124.222.233.153/">Home</a>&nbsp;»&nbsp;<a href="http://124.222.233.153/posts/">Essays</a>&nbsp;»&nbsp;<a href="http://124.222.233.153/posts/tech/">🤖 Technology</a>&nbsp;»&nbsp;<a href="http://124.222.233.153/posts/tech/se/">🧑‍💻 Software Engineering</a></div>
    <h1 class="post-title">
      Kafka Start
    </h1>
    <div class="post-meta"><span title='2023-03-07 23:33:20 +0800 CST'>March 7, 2023</span>&nbsp;·&nbsp;River

</div>
  </header> 
<figure class="entry-cover1"><img loading="lazy" src="http://124.222.233.153/images/kafka.png" alt="">
        
</figure><aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#kafka-%e5%85%a5%e9%97%a8%e6%8c%87%e5%8d%97" aria-label="kafka 入门指南">kafka 入门指南</a><ul>
                            
                    <li>
                        <a href="#1-kafka-%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5%e4%b8%8e%e5%9f%ba%e6%9c%ac%e6%9e%b6%e6%9e%84" aria-label="1. kafka 基本概念与基本架构">1. kafka 基本概念与基本架构</a></li>
                    <li>
                        <a href="#2-kafka-%e5%8d%95%e6%9c%ba%e7%8e%af%e5%a2%83%e6%90%ad%e5%bb%ba-%e4%b8%8e-%e5%90%af%e5%8a%a8" aria-label="2. kafka 单机环境搭建 与 启动">2. kafka 单机环境搭建 与 启动</a><ul>
                            
                    <li>
                        <a href="#21-%e4%b8%8b%e8%bd%bdkafka%e5%ae%89%e8%a3%85%e5%8c%85%e4%b8%8a%e4%bc%a0%e6%9c%8d%e5%8a%a1%e5%99%a8" aria-label="2.1 下载Kafka安装包上传服务器">2.1 下载Kafka安装包上传服务器</a></li>
                    <li>
                        <a href="#22-%e9%85%8d%e7%bd%aezookeeper%e9%85%8d%e7%bd%ae" aria-label="2.2 配置zookeeper配置">2.2 配置zookeeper配置</a></li>
                    <li>
                        <a href="#23-%e9%85%8d%e7%bd%aekafka%e9%85%8d%e7%bd%aeserver" aria-label="2.3 配置kafka配置（server）">2.3 配置kafka配置（server）</a></li>
                    <li>
                        <a href="#24-%e5%90%8e%e5%8f%b0%e5%90%af%e5%8a%a8zookeeper%e5%b9%b6%e6%a3%80%e9%aa%8c%e6%98%af%e5%90%a6%e8%bf%90%e8%a1%8c%e6%88%90%e5%8a%9f" aria-label="2.4 后台启动zookeeper并检验是否运行成功">2.4 后台启动zookeeper并检验是否运行成功</a></li>
                    <li>
                        <a href="#25-%e5%90%8e%e5%8f%b0%e5%90%af%e5%8a%a8kafka" aria-label="2.5 后台启动kafka">2.5 后台启动kafka</a></li>
                    <li>
                        <a href="#26-%e5%88%9b%e5%bb%ba%e5%b9%b6%e6%9f%a5%e7%9c%8btopic" aria-label="2.6 创建并查看topic">2.6 创建并查看topic</a></li></ul>
                    </li>
                    <li>
                        <a href="#3-java%e5%ae%9e%e7%8e%b0-kafka-producer" aria-label="3. JAVA实现 Kafka Producer">3. JAVA实现 Kafka Producer</a><ul>
                            
                    <li>
                        <a href="#31-%e6%96%b9%e5%bc%8f%e4%b8%80kafka-clients" aria-label="3.1 方式一：kafka-clients">3.1 方式一：kafka-clients</a><ul>
                            
                    <li>
                        <a href="#%e5%bc%95%e5%85%a5kafka-clients%e4%be%9d%e8%b5%96" aria-label="引入kafka-clients依赖">引入kafka-clients依赖</a></li>
                    <li>
                        <a href="#%e5%88%9b%e5%bb%ba%e7%94%9f%e4%ba%a7%e8%80%85-kafkaproducer" aria-label="创建生产者 KafkaProducer">创建生产者 KafkaProducer</a></li>
                    <li>
                        <a href="#%e5%8f%91%e9%80%81%e6%b6%88%e6%81%af" aria-label="发送消息">发送消息</a></li></ul>
                    </li></ul>
                    </li>
                    <li>
                        <a href="#4-java%e5%ae%9e%e7%8e%b0-kafka-consumer" aria-label="4. JAVA实现 Kafka Consumer">4. JAVA实现 Kafka Consumer</a><ul>
                            
                    <li>
                        <a href="#41-%e6%96%b9%e5%bc%8f%e4%b8%80kaf%e7%99%bb%e5%bd%95%e6%96%87%e4%bb%b6%e6%8f%90%e4%ba%a4%e5%90%8e%e8%87%aa%e5%8a%a8%e9%87%8d%e5%91%bd%e5%90%8d%e6%94%af%e6%8c%81%e6%94%b6%e9%9b%86%e4%bb%bb%e6%84%8f%e6%a0%bc%e5%bc%8f%e6%96%87%e4%bb%b6" aria-label="4.1 方式一：kaf登录，文件提交后自动重命名，支持收集任意格式文件。">4.1 方式一：kaf登录，文件提交后自动重命名，支持收集任意格式文件。</a><ul>
                            
                    <li>
                        <a href="#%e5%bc%95%e5%85%a5kafka-clients%e4%be%9d%e8%b5%96-1" aria-label="引入kafka-clients依赖">引入kafka-clients依赖</a></li>
                    <li>
                        <a href="#%e5%88%9b%e5%bb%ba%e6%b6%88%e8%b4%b9%e8%80%85-kafkaconsumer" aria-label="创建消费者 KafkaConsumer">创建消费者 KafkaConsumer</a></li>
                    <li>
                        <a href="#%e8%ae%a2%e9%98%85%e4%b8%bb%e9%a2%98topic" aria-label="订阅主题Topic">订阅主题Topic</a></li>
                    <li>
                        <a href="#%e6%b6%88%e8%b4%b9%e8%bd%ae%e8%af%a2%e6%a0%b8%e5%bf%83" aria-label="消费轮询（核心）">消费轮询（核心）</a>
                    </li>
                </ul>
                </li>
                </ul>
                </li>
                </ul>
                </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>


  <div class="post-content"><h1 id="kafka-入门指南">kafka 入门指南<a hidden class="anchor" aria-hidden="true" href="#kafka-入门指南">#</a></h1>
<h2 id="1-kafka-基本概念与基本架构">1. kafka 基本概念与基本架构<a hidden class="anchor" aria-hidden="true" href="#1-kafka-基本概念与基本架构">#</a></h2>
<h2 id="2-kafka-单机环境搭建-与-启动">2. kafka 单机环境搭建 与 启动<a hidden class="anchor" aria-hidden="true" href="#2-kafka-单机环境搭建-与-启动">#</a></h2>
<p>参考：</p>
<ol>
<li><a href="https://blog.csdn.net/CSDN877425287/article/details/108836682">https://blog.csdn.net/CSDN877425287/article/details/108836682</a></li>
<li><a href="https://www.cnblogs.com/qpf1/p/9161742.html">https://www.cnblogs.com/qpf1/p/9161742.html</a></li>
</ol>
<p>扩展（kafka生产环境部署指南）:</p>
<p><a href="https://xie.infoq.cn/article/d57f83779490c7ff62b6b59ae">kafka生产环境部署指南</a></p>
<h3 id="21-下载kafka安装包上传服务器">2.1 下载Kafka安装包上传服务器<a hidden class="anchor" aria-hidden="true" href="#21-下载kafka安装包上传服务器">#</a></h3>
<p><a href="https://kafka.apache.org/downloads">kafka官网</a></p>
<p><img loading="lazy" src="https://zzp-note.oss-cn-hangzhou.aliyuncs.com/image/image-20221116231239045.png" alt="image-20221116231239045"  />
</p>
<p>scp 指令上传服务器</p>
<p><code>tar xzvf kafka_2.12-2.1.0.tgz -C /home/ubuntu/environments</code></p>
<h3 id="22-配置zookeeper配置">2.2 配置zookeeper配置<a hidden class="anchor" aria-hidden="true" href="#22-配置zookeeper配置">#</a></h3>
<p>无需单独下载，已经集成</p>
<p><code>vim ./kafka_2.12-2.1.0/config/zookeeper.properties</code></p>
<p>如果kafka和zk是单节点运行的话使用kafka的默认配置即可</p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>#集群配置-单节点无需配置
</span></span><span style="display:flex;"><span>server.1=192.168.0.187:2888:3888
</span></span><span style="display:flex;"><span>server.2=192.168.0.188:2888:3888
</span></span><span style="display:flex;"><span>server.3=192.168.0.189:2888:3888
</span></span></code></pre></div><p><img loading="lazy" src="https://zzp-note.oss-cn-hangzhou.aliyuncs.com/image/image-20221116232713399.png" alt="image-20221116232713399"  />
</p>
<p><strong><code>dataDir</code> zk数据存放目录</strong></p>
<p><code>dataLogDir</code> zk日志存放目录</p>
<p><strong><code>clientPort</code> 客户端连接zk服务的端口</strong></p>
<p><code>tickTime</code> zk服务器之间或者客户端与服务器之间维持心跳的时间间隔</p>
<p><code>initLimit</code> 允许follower（相对于Leaderer言的，客户端）连接并同步到Leader的初始化连接时间，以tickTime为单位，当初始化连接时间超过该值，则表示连接失败。</p>
<p><code>syncLimit</code> Leader于Follower之间发送消息时，请求和答应时间长度，如果follow在设置时间内不能与leader通信，那么此follower将会被丢弃</p>
<p><code>server.1=192.168.0.187:2888:3888</code> 2888是follower于leader减缓信息的端口，3888当leader交换信息的端口，3888是当leader挂了时用来执行选举是服务器互相通信的端口</p>
<h3 id="23-配置kafka配置server">2.3 配置kafka配置（server）<a hidden class="anchor" aria-hidden="true" href="#23-配置kafka配置server">#</a></h3>
<p><strong>如果kafka和zk是单节点运行的话使用kafka的默认配置即可</strong></p>
<p>关键：</p>
<p><strong>log.dirs和zookeeper.connect。前者是日志存放文件夹，后者是zookeeper连接地址（端口和clientPort保持一致）。</strong></p>
<ul>
<li><strong>listeners</strong></li>
<li><strong>advertised.listeners</strong>（对外宣扬/暴露的地址和端口，比如对生产者、消费者暴露）</li>
</ul>
<p>在公司内网部署 kafka 集群只需要用到 listeners，内外网需要作区分时 才需要用到advertised.listeners。</p>
<p>advertised_listeners 监听器会注册在 zookeeper 中；</p>
<p>当我们对 172.17.0.10:9092 请求建立连接，kafka 服务器会通过 zookeeper 中注册的监听器，找到 INSIDE 监听器，然后通过 listeners 中找到对应的 通讯 ip 和 端口；</p>
<p>同理，当我们对 &lt;公网 ip&gt;:端口 请求建立连接，kafka 服务器会通过 zookeeper 中注册的监听器，找到 OUTSIDE 监听器，然后通过 listeners 中找到对应的 通讯 ip 和 端口 172.17.0.10:9094；</p>
<p>总结：advertised_listeners 是对外暴露的服务端口，真正建立连接用的是 listeners。</p>
<ul>
<li>只有内网，比如在公司搭建的 kafka 集群，只有内网中的服务可以用，这种情况下，只需要用 listeners 就行。</li>
<li>内外网，比如在 docker 中或者 在类似阿里云主机上部署 kafka 集群，这种情况下是 需要用到 advertised_listeners</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>broker.id=0									每个server需要单独配置broker.id如果不配置系统会指定配置，需要和上一步ID一致
</span></span><span style="display:flex;"><span>listeners=PLAINTEST://ip:9092				监听地址，格式PLAINTEST：//ip：端口
</span></span><span style="display:flex;"><span>num.network.threads=3						接收和发送网络信息的线程数
</span></span><span style="display:flex;"><span>num.io.threads=8							服务器用于处理请求的线程数，其中可能包括磁盘IO
</span></span><span style="display:flex;"><span>socket.send.buffer.bytes=102400				套接字服务器使用的发送缓冲区（SO_SNDBUF）
</span></span><span style="display:flex;"><span>socket.receive.buffer.bytes=102400			套接字服务器使用的接收缓冲区（SO_RCVBUF）
</span></span><span style="display:flex;"><span>socket.request.max.bytes=104857600			套接字服务器将接收的请求最大大小（防止OOM）
</span></span><span style="display:flex;"><span>log.dirs=/tmp/kafka-logs					日志文件
</span></span><span style="display:flex;"><span>num.partitions=1							partitions的数量
</span></span><span style="display:flex;"><span>num.recovery.threads.per.data.dir=1			启动时恢复日志，关闭时刷盘日志每个数据目录的线程的数量，默认1
</span></span><span style="display:flex;"><span>offsets.topic.replication.factor=1			偏移量话题的复制因子（设置更高保证可用），为保证有效的父子，偏移量的复制因子是可配置的，在偏移话题的第一次请求的时候可用borker的数量至少为复制因子的大小，否则要么话题创建失败，要么复制因子取可用的数量和配置复制因子取最小值
</span></span><span style="display:flex;"><span>transaction.state.log.replication.factor=1
</span></span><span style="display:flex;"><span>transaction.state.log.min.isr=1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>log.retention.hours=168						日志文件删除之前保留的时间
</span></span><span style="display:flex;"><span>log.segment.bytes=1073741824				单个日志文件大小默认为1073741824
</span></span><span style="display:flex;"><span>log.retention.check.interval.ms=300000		检查日志端以查看是否可以根据保留策略删除他们的时间鳄梨
</span></span><span style="display:flex;"><span>zookeeper.connect=zkip:2181					zk主机地址，如果是zk集群以逗号分隔
</span></span><span style="display:flex;"><span>zookeeper.connection.timeout.ms=6000		连接zk的超时时间
</span></span><span style="display:flex;"><span>group.initial.rebalance.delay.ms=0
</span></span></code></pre></div><h3 id="24-后台启动zookeeper并检验是否运行成功">2.4 后台启动zookeeper并检验是否运行成功<a hidden class="anchor" aria-hidden="true" href="#24-后台启动zookeeper并检验是否运行成功">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">cd</span> kafka_2.12-2.1.0/
</span></span><span style="display:flex;"><span>nohup bin/zookeeper-server-start.sh config/zookeeper.properties &amp;
</span></span><span style="display:flex;"><span>nohup bin/zookeeper-server-start.sh config/zookeeper.properties &gt; zookeeper-run.log 2&gt;&amp;<span style="color:#ff0;font-weight:bold">1</span> &amp;
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">echo</span> conf | nc localhost <span style="color:#ff0;font-weight:bold">2181</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">echo</span> stat | nc localhost <span style="color:#ff0;font-weight:bold">2181</span>
</span></span></code></pre></div><p><img loading="lazy" src="https://zzp-note.oss-cn-hangzhou.aliyuncs.com/image/image-20221116234427027.png" alt="image-20221116234427027"  />
</p>
<h3 id="25-后台启动kafka">2.5 后台启动kafka<a hidden class="anchor" aria-hidden="true" href="#25-后台启动kafka">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>nohup bin/kafka-server-start.sh config/server.properties &gt; kafka-run.log 2&gt;&amp;<span style="color:#ff0;font-weight:bold">1</span> &amp;
</span></span></code></pre></div><h3 id="26-创建并查看topic">2.6 创建并查看topic<a hidden class="anchor" aria-hidden="true" href="#26-创建并查看topic">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>ubuntu$&gt; ./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor <span style="color:#ff0;font-weight:bold">1</span> --partitions <span style="color:#ff0;font-weight:bold">1</span> --topic <span style="color:#fff;font-weight:bold">test</span>
</span></span><span style="display:flex;"><span>Created topic <span style="color:#0ff;font-weight:bold">&#34;test&#34;</span>.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ubuntu$&gt; ./bin/kafka-topics.sh --zookeeper localhost:2181 --list
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">test</span>
</span></span></code></pre></div><h2 id="3-java实现-kafka-producer">3. JAVA实现 Kafka Producer<a hidden class="anchor" aria-hidden="true" href="#3-java实现-kafka-producer">#</a></h2>
<h3 id="31-方式一kafka-clients">3.1 方式一：kafka-clients<a hidden class="anchor" aria-hidden="true" href="#31-方式一kafka-clients">#</a></h3>
<p>API参考：https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html</p>
<p>生产者详解、进阶参考：https://www.jianshu.com/p/37ea14d1d4ab（主要包含生产者参数配置、消息序列化、自定义分区）</p>
<h4 id="引入kafka-clients依赖">引入kafka-clients依赖<a hidden class="anchor" aria-hidden="true" href="#引入kafka-clients依赖">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="font-weight:bold">&lt;dependency&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">&lt;groupId&gt;</span>org.apache.kafka<span style="font-weight:bold">&lt;/groupId&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">&lt;artifactId&gt;</span>kafka-clients<span style="font-weight:bold">&lt;/artifactId&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">&lt;version&gt;</span>2.1.0<span style="font-weight:bold">&lt;/version&gt;</span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">&lt;/dependency&gt;</span>
</span></span></code></pre></div><h4 id="创建生产者-kafkaproducer">创建生产者 KafkaProducer<a hidden class="anchor" aria-hidden="true" href="#创建生产者-kafkaproducer">#</a></h4>
<p><code>KafkaProducer</code> API: <a href="https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html">https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html</a></p>
<p>向 Kafka 写入消息，首先要创建一个生产者对象，该对象有3个必要属性。</p>
<ul>
<li><code>bootstrap.servers</code>
指定 broker 的地址列表，地址的格式为 <code>host:port</code>。
不需要包含所有的 broker 地址，生产者会通过给定的 broker 查找到其他 broker 的信息。建议至少提供两个 broker 的信息，防止其中一个宕机。</li>
<li><code>key.serializer</code>
Kafka 客户端默认提供了 <code>ByteArraySerializer</code>、 <code>StringSerializer</code> 和 <code>IntegerSerializer</code>，因此如果使用常见的 Java 对象类型，不需要实现自己的序列化器 。如果要自定义序列化器，需要实现 <code>org.apache.kafka.common.serialization.Serializer</code> 接口。
需要注意，key.serializer 是必须设置的，即使只发送值类型。</li>
<li><code>value.serializer</code>
与 <code>key.serializer</code> 一样， <code>value.serializer</code> 指定的类会将值序列化发送给 broker。</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span>        Properties kafkaProps = <span style="color:#fff;font-weight:bold">new</span> Properties();
</span></span><span style="display:flex;"><span>        kafkaProps.<span style="color:#007f7f">put</span>(ProducerConfig.<span style="color:#007f7f">BOOTSTRAP_SERVERS_CONFIG</span>, <span style="color:#0ff;font-weight:bold">&#34;kafka-broker-ip:9092&#34;</span>);
</span></span><span style="display:flex;"><span>        kafkaProps.<span style="color:#007f7f">put</span>(ProducerConfig.<span style="color:#007f7f">KEY_SERIALIZER_CLASS_CONFIG</span>, StringSerializer.<span style="color:#007f7f">class</span>.<span style="color:#007f7f">getName</span>());
</span></span><span style="display:flex;"><span>        kafkaProps.<span style="color:#007f7f">put</span>(ProducerConfig.<span style="color:#007f7f">VALUE_SERIALIZER_CLASS_CONFIG</span>, StringSerializer.<span style="color:#007f7f">class</span>.<span style="color:#007f7f">getName</span>());
</span></span><span style="display:flex;"><span>        KafkaProducer&lt;String, String&gt; producer = <span style="color:#fff;font-weight:bold">new</span> KafkaProducer&lt;String, String&gt;(kafkaProps);
</span></span></code></pre></div><h4 id="发送消息">发送消息<a hidden class="anchor" aria-hidden="true" href="#发送消息">#</a></h4>
<p>实例化生产者对象后，就可以开始送消息了。发送消息主要有以下 3 种方式：</p>
<ul>
<li>发送并忘记（fire-and-forget）
把消息发送给服务器，不关心是否正常到达。大多数情况下，消息会正常到达，因为  Kafka 是高可用的，而且生产者会自动尝试重发。不过，使用这种方式有时候也会丢失一些消息。</li>
<li>同步发送（async）
使用 <code>send()</code> 方法发送消息，会返回一个 Future 对象，调用 get() 方法阻塞等待返回，返回结果知道是否发送成功。</li>
<li><strong>异步发送（sync）</strong>（最简单最常用）
使用 <code>send()</code> 方法并指定一个回调函数，服务器在返回响应时调用该函数。</li>
</ul>
<p>核心对象：</p>
<ul>
<li>消息对象 <code>ProducerRecord</code> : <a href="https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html">https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html</a></li>
<li>消息记录的存储信息 <code>RecordMetadata</code>： <a href="https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html">https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html</a>（<code>send(...).get()</code>返回对象）</li>
</ul>
<p>例子使用了ScheduledExecutorServive（即ScheduledThreadPool）来进行定时任务</p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span>        ScheduledExecutorService scheduledExecutor = Executors.<span style="color:#007f7f">newScheduledThreadPool</span>(<span style="color:#ff0;font-weight:bold">5</span>);
</span></span><span style="display:flex;"><span>        scheduledExecutor.<span style="color:#007f7f">scheduleAtFixedRate</span>(() -&gt; {
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">try</span> {
</span></span><span style="display:flex;"><span>                RecordMetadata recordMetadata = producer.<span style="color:#007f7f">send</span>(<span style="color:#fff;font-weight:bold">new</span> ProducerRecord&lt;String, String&gt;(<span style="color:#0ff;font-weight:bold">&#34;test&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;time&#34;</span>, <span style="color:#fff;font-weight:bold">new</span> Date().<span style="color:#007f7f">toString</span>())).<span style="color:#007f7f">get</span>();
</span></span><span style="display:flex;"><span>                System.<span style="color:#007f7f">out</span>.<span style="color:#007f7f">println</span>(<span style="color:#0ff;font-weight:bold">&#34;Success: OFFSET-&#34;</span>+recordMetadata.<span style="color:#007f7f">offset</span>());
</span></span><span style="display:flex;"><span>            } <span style="color:#fff;font-weight:bold">catch</span> (InterruptedException e) {
</span></span><span style="display:flex;"><span>                System.<span style="color:#007f7f">out</span>.<span style="color:#007f7f">println</span>(<span style="color:#0ff;font-weight:bold">&#34;ERROR&#34;</span>);
</span></span><span style="display:flex;"><span>                <span style="color:#fff;font-weight:bold">throw</span> <span style="color:#fff;font-weight:bold">new</span> RuntimeException(e);
</span></span><span style="display:flex;"><span>            } <span style="color:#fff;font-weight:bold">catch</span> (ExecutionException e) {
</span></span><span style="display:flex;"><span>                System.<span style="color:#007f7f">out</span>.<span style="color:#007f7f">println</span>(<span style="color:#0ff;font-weight:bold">&#34;ERROR&#34;</span>);
</span></span><span style="display:flex;"><span>                <span style="color:#fff;font-weight:bold">throw</span> <span style="color:#fff;font-weight:bold">new</span> RuntimeException(e);
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }, <span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#ff0;font-weight:bold">2</span>, TimeUnit.<span style="color:#007f7f">SECONDS</span>);
</span></span></code></pre></div><h2 id="4-java实现-kafka-consumer">4. JAVA实现 Kafka Consumer<a hidden class="anchor" aria-hidden="true" href="#4-java实现-kafka-consumer">#</a></h2>
<h3 id="41-方式一kaf登录文件提交后自动重命名支持收集任意格式文件">4.1 方式一：kaf登录，文件提交后自动重命名，支持收集任意格式文件。<a hidden class="anchor" aria-hidden="true" href="#41-方式一kaf登录文件提交后自动重命名支持收集任意格式文件">#</a></h3>
<p>搭配坚果云ka-clients</p>
<p>API 参考：https://kafka.apache.org/33/javadoc/org/apache/kafka/clients/consumer/package-frame.html</p>
<p>消费者详解、进阶参考：https://www.jianshu.com/p/1f9e18e926f6（主要包括消费者参数配置</p>
<h4 id="引入kafka-clients依赖-1">引入kafka-clients依赖<a hidden class="anchor" aria-hidden="true" href="#引入kafka-clients依赖-1">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="font-weight:bold">&lt;dependency&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">&lt;groupId&gt;</span>org.apache.kafka<span style="font-weight:bold">&lt;/groupId&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">&lt;artifactId&gt;</span>kafka-clients<span style="font-weight:bold">&lt;/artifactId&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">&lt;version&gt;</span>2.1.0<span style="font-weight:bold">&lt;/version&gt;</span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">&lt;/dependency&gt;</span>
</span></span></code></pre></div><h4 id="创建消费者-kafkaconsumer">创建消费者 KafkaConsumer<a hidden class="anchor" aria-hidden="true" href="#创建消费者-kafkaconsumer">#</a></h4>
<ul>
<li>KafkaConsumer对象API：https://kafka.apache.org/33/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html</li>
<li>ConsumerConfig API：https://kafka.apache.org/33/javadoc/org/apache/kafka/clients/consumer/ConsumerConfig.html</li>
</ul>
<p><strong>auto.offset.reset</strong>：当不存在初始偏移量或服务器上不再存在当前偏移量时，此属性是必需的。只有以下三个值可用于重置偏移值：</p>
<p>What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server (e.g. because that data has been deleted):</p>
<ul><li>earliest: automatically reset the offset to the earliest offset<li>latest: automatically reset the offset to the latest offset</li><li>none: throw exception to the consumer if no previous offset is found for the consumer\'s group</li><li>anything else: throw exception to the consumer.</li></ul>
<p>指定了消费者在读取一个没有偏移量（offset）的分区或者偏移量无效的情况下（因消费者长时间失效，包含偏移量的记录已经过时井被删除）该作何处理，<strong>默认值是 <code>latest</code>，表示在 offset 无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）</strong>。</p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span>        Properties props = <span style="color:#fff;font-weight:bold">new</span> Properties();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        props.<span style="color:#007f7f">put</span>(ConsumerConfig.<span style="color:#007f7f">BOOTSTRAP_SERVERS_CONFIG</span>, <span style="color:#0ff;font-weight:bold">&#34;124.222.233.153:9092&#34;</span>);
</span></span><span style="display:flex;"><span>        props.<span style="color:#007f7f">put</span>(ConsumerConfig.<span style="color:#007f7f">GROUP_ID_CONFIG</span>, <span style="color:#0ff;font-weight:bold">&#34;191870267-0&#34;</span>);
</span></span><span style="display:flex;"><span>        props.<span style="color:#007f7f">put</span>(ConsumerConfig.<span style="color:#007f7f">KEY_DESERIALIZER_CLASS_CONFIG</span>, StringDeserializer.<span style="color:#007f7f">class</span>.<span style="color:#007f7f">getName</span>());
</span></span><span style="display:flex;"><span>        props.<span style="color:#007f7f">put</span>(ConsumerConfig.<span style="color:#007f7f">VALUE_DESERIALIZER_CLASS_CONFIG</span>, StringDeserializer.<span style="color:#007f7f">class</span>.<span style="color:#007f7f">getName</span>());
</span></span><span style="display:flex;"><span>		props.<span style="color:#007f7f">put</span>(ConsumerConfig.<span style="color:#007f7f">AUTO_OFFSET_RESET_CONFIG</span>, <span style="color:#0ff;font-weight:bold">&#34;earliest&#34;</span>);
</span></span><span style="display:flex;"><span>        props.<span style="color:#007f7f">put</span>(ConsumerConfig.<span style="color:#007f7f">MAX_POLL_RECORDS_CONFIG</span>, <span style="color:#0ff;font-weight:bold">&#34;10&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        KafkaConsumer&lt;String, String&gt; consumer = <span style="color:#fff;font-weight:bold">new</span> KafkaConsumer&lt;String, String&gt;(props);
</span></span></code></pre></div><h4 id="订阅主题topic">订阅主题Topic<a hidden class="anchor" aria-hidden="true" href="#订阅主题topic">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span>consumer.<span style="color:#007f7f">subscribe</span>(Collections.<span style="color:#007f7f">singleton</span>(<span style="color:#0ff;font-weight:bold">&#34;test&#34;</span>));
</span></span></code></pre></div><h4 id="消费轮询核心">消费轮询（核心）<a hidden class="anchor" aria-hidden="true" href="#消费轮询核心">#</a></h4>
<p>消息轮询是消费者的核心，通过轮询向服务器请求数据。消息轮询 API 会处理所有的细节，包括群组协调、分区再均衡、发送心跳和获取数据，开发者只需要处理从分区返回的数据。</p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">while</span> (<span style="color:#fff;font-weight:bold">true</span>) {
</span></span><span style="display:flex;"><span>            ConsumerRecords&lt;String, String&gt; records = consumer.<span style="color:#007f7f">poll</span>(Duration.<span style="color:#007f7f">ofSeconds</span>(<span style="color:#ff0;font-weight:bold">5</span>));
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">for</span>(ConsumerRecord&lt;String, String&gt; record : records) {
</span></span><span style="display:flex;"><span>                System.<span style="color:#007f7f">out</span>.<span style="color:#007f7f">println</span>(<span style="color:#0ff;font-weight:bold">&#34;{offset=&#34;</span> + record.<span style="color:#007f7f">offset</span>() + <span style="color:#0ff;font-weight:bold">&#34; , key=&#34;</span> + record.<span style="color:#007f7f">key</span>() + <span style="color:#0ff;font-weight:bold">&#34; , value=&#34;</span> + record.<span style="color:#007f7f">value</span>() + <span style="color:#0ff;font-weight:bold">&#34; , timestamp=&#34;</span> + record.<span style="color:#007f7f">timestamp</span>() + <span style="color:#0ff;font-weight:bold">&#34; }&#34;</span>);
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>            System.<span style="color:#007f7f">out</span>.<span style="color:#007f7f">println</span>();
</span></span><span style="display:flex;"><span>        }
</span></span></code></pre></div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://124.222.233.153/tags/kafka/">kafka</a></li>
    </ul>

  </footer>
<div>
    <div class="pagination__title">
        <span class="pagination__title-h" style="font-size: 20px;">💬 Comments</span>
        <hr />
    </div>
    <div id="tcomment"></div>
    <script src="https://cdn.staticfile.org/twikoo/1.6.10/twikoo.all.min.js"></script>
    <script>
        twikoo.init({
            envId: "https://twikoo-for-river-blog.vercel.app",  
            el: "#tcomment",
            lang: 'zh-CN',
            
            path: window.TWIKOO_MAGIC_PATH||window.location.pathname,
        });
    </script>
</div>

</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="http://124.222.233.153/">River&#39;s BLOG</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
